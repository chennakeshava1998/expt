{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/eager#object_based_saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "from TPM_from_VCS.data import toy_data_generator\n",
    "from TPM_from_VCS.models.etp import etp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes currently : 73\n",
      "Completed VC processing\n",
      "Trainable Variables : []\n",
      "Current best of count_invs = 100 at Angle 0\n",
      "Current best of count_invs = 100 at Angle 60\n",
      "Current best of count_invs = 100 at Angle 120\n",
      "Current best of count_invs = 100 at Angle 180\n",
      "Current best of count_invs = 100 at Angle 240\n",
      "Current best of count_invs = 100 at Angle 300\n",
      "Initial loss: 10000.000\n",
      "Current best of count_invs = 100 at Angle 0\n",
      "Current best of count_invs = 100 at Angle 60\n",
      "Current best of count_invs = 100 at Angle 120\n",
      "Current best of count_invs = 100 at Angle 180\n",
      "Current best of count_invs = 100 at Angle 240\n",
      "Current best of count_invs = 100 at Angle 300\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: [\"<tf.Variable 'weight:0' shape=(2, 5) dtype=float64, numpy=\\narray([[ 0.86722115, -0.13467919, -0.76492871,  2.00068491, -0.46708356],\\n       [ 0.07439112, -0.63784151,  1.47998238, -0.37473334, -2.16849162]])>\", \"<tf.Variable 'bias:0' shape=(2, 1) dtype=float64, numpy=\\narray([[-0.32934049],\\n       [ 1.1795365 ]])>\"].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-eeb130fa858c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m       optimizer.apply_gradients(zip(grads, [model.W, model.B]),\n\u001b[0;32m---> 41\u001b[0;31m                                 global_step=tf.train.get_or_create_global_step())\n\u001b[0m\u001b[1;32m     42\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss at step {:03d}: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, global_step, name)\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m       raise ValueError(\"No gradients provided for any variable: %s.\" %\n\u001b[0;32m--> 593\u001b[0;31m                        ([str(v) for _, v, _ in converted_grads_and_vars],))\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_slots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: [\"<tf.Variable 'weight:0' shape=(2, 5) dtype=float64, numpy=\\narray([[ 0.86722115, -0.13467919, -0.76492871,  2.00068491, -0.46708356],\\n       [ 0.07439112, -0.63784151,  1.47998238, -0.37473334, -2.16849162]])>\", \"<tf.Variable 'bias:0' shape=(2, 1) dtype=float64, numpy=\\narray([[-0.32934049],\\n       [ 1.1795365 ]])>\"]."
     ]
    }
   ],
   "source": [
    "class Model(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(Model, self).__init__()\n",
    "    self.W = tf.Variable(tf.random_normal((2, 5), dtype=tf.float64), name='weight', trainable=True)\n",
    "    self.B = tf.Variable(tf.random_normal((2, 1), dtype=tf.float64), name='bias', trainable=True)\n",
    "\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    return tf.add(tf.matmul(self.W, tf.reshape(inputs, (5, -1))), self.B)\n",
    "\n",
    "# The loss function to be optimized\n",
    "def loss(model, inputs, targets):\n",
    "#   target = tf.cast(target, dtype=tf.float64)\n",
    "  ans = etp.get_best_etp(model(inputs), targets)\n",
    "  return tf.reduce_mean(tf.square(ans))\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs, tf.cast(targets, dtype=tf.float64))\n",
    "  return tape.gradient(loss_value, [model.W, model.B])\n",
    "\n",
    "# Define:\n",
    "# 1. A model.\n",
    "# 2. Derivatives of a loss function with respect to model parameters.\n",
    "# 3. A strategy for updating the variables based on the derivatives.\n",
    "model = Model()\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "\n",
    "a = toy_data_generator.create_dataset(1)\n",
    "training_inputs = a[0][0]\n",
    "training_outputs = a[0][1]\n",
    "print('Trainable Variables : {}'.format(tf.trainable_variables()))\n",
    "\n",
    "print(\"Initial loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n",
    "\n",
    "# Training loop\n",
    "for j in range(10):\n",
    "    for i in range(300):\n",
    "      grads = grad(model, training_inputs, training_outputs)\n",
    "      optimizer.apply_gradients(zip(grads, [model.W, model.B]),\n",
    "                                global_step=tf.train.get_or_create_global_step())\n",
    "      if i % 20 == 0:\n",
    "        print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model, training_inputs, training_outputs)))\n",
    "        \n",
    "    a = toy_data_generator.create_dataset(1)\n",
    "    training_inputs = a[0][0]\n",
    "    training_outputs = a[0][1]\n",
    "\n",
    "print(\"Final loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n",
    "print(\"W = {}, B = {}\".format(model.W.numpy(), model.B.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 90\n",
    "rot_matrix = np.array([[np.cos(np.radians(x)), -np.sin(np.radians(x))], [np.sin(np.radians(x)), np.cos(np.radians(x))]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(rot_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = toy_data_generator.create_dataset(1)\n",
    "inputs = a[0][0]\n",
    "outputs = a[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.matmul(tf.convert_to_tensor(rot_matrix), tf.reshape(outputs, shape=(2, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.matmul((rot_matrix), tf.reshape(outputs, shape=(2, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/summaries_and_tensorboard   : use tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/40050397/deep-learning-nan-loss-reasons"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
